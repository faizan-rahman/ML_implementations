{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Download dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x193891f7fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIn/HDR9CLRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19388835940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(mnist.train.images[5].reshape(28,28),cmap='gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Placeholders__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32,shape=[None,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Helper Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Setup Layers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_1 = convolutional_layer(x_image,shape=[6,6,1,32])\n",
    "convo_1_pooling = max_pool_2by2(convo_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[6,6,32,64])\n",
    "convo_2_pooling = max_pool_2by2(convo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1,7*7*64])\n",
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hold_prob = tf.placeholder(tf.float32)\n",
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loss Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Optimizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Graph Session__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.0949\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.8339\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.9091\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.9287\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.9356\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.9483\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.9494\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.9552\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.9589\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.9595\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.9639\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.9639\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.966\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.9686\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.9695\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.9718\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.973\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.9725\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.9738\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.9757\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.9742\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.9757\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.9763\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "0.9771\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.9794\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.9791\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.9779\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.9794\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.9811\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.9796\n",
      "\n",
      "\n",
      "Currently on step 3000\n",
      "Accuracy is:\n",
      "0.9797\n",
      "\n",
      "\n",
      "Currently on step 3100\n",
      "Accuracy is:\n",
      "0.9813\n",
      "\n",
      "\n",
      "Currently on step 3200\n",
      "Accuracy is:\n",
      "0.982\n",
      "\n",
      "\n",
      "Currently on step 3300\n",
      "Accuracy is:\n",
      "0.9819\n",
      "\n",
      "\n",
      "Currently on step 3400\n",
      "Accuracy is:\n",
      "0.983\n",
      "\n",
      "\n",
      "Currently on step 3500\n",
      "Accuracy is:\n",
      "0.9821\n",
      "\n",
      "\n",
      "Currently on step 3600\n",
      "Accuracy is:\n",
      "0.9838\n",
      "\n",
      "\n",
      "Currently on step 3700\n",
      "Accuracy is:\n",
      "0.984\n",
      "\n",
      "\n",
      "Currently on step 3800\n",
      "Accuracy is:\n",
      "0.9828\n",
      "\n",
      "\n",
      "Currently on step 3900\n",
      "Accuracy is:\n",
      "0.9851\n",
      "\n",
      "\n",
      "Currently on step 4000\n",
      "Accuracy is:\n",
      "0.9847\n",
      "\n",
      "\n",
      "Currently on step 4100\n",
      "Accuracy is:\n",
      "0.9848\n",
      "\n",
      "\n",
      "Currently on step 4200\n",
      "Accuracy is:\n",
      "0.9844\n",
      "\n",
      "\n",
      "Currently on step 4300\n",
      "Accuracy is:\n",
      "0.9843\n",
      "\n",
      "\n",
      "Currently on step 4400\n",
      "Accuracy is:\n",
      "0.9833\n",
      "\n",
      "\n",
      "Currently on step 4500\n",
      "Accuracy is:\n",
      "0.9842\n",
      "\n",
      "\n",
      "Currently on step 4600\n",
      "Accuracy is:\n",
      "0.9845\n",
      "\n",
      "\n",
      "Currently on step 4700\n",
      "Accuracy is:\n",
      "0.9859\n",
      "\n",
      "\n",
      "Currently on step 4800\n",
      "Accuracy is:\n",
      "0.9854\n",
      "\n",
      "\n",
      "Currently on step 4900\n",
      "Accuracy is:\n",
      "0.9856\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = 5000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(steps):\n",
    "        \n",
    "        batch_x , batch_y = mnist.train.next_batch(50)\n",
    "        \n",
    "        sess.run(train,feed_dict={x:batch_x,y_true:batch_y,hold_prob:0.5})\n",
    "        \n",
    "        # PRINT OUT A MESSAGE EVERY 100 STEPS\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:mnist.test.images,y_true:mnist.test.labels,hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
